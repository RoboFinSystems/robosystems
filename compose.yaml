services:
  # Robosystems API
  api:
    container_name: robosystems-api
    build:
      context: .
      dockerfile: Dockerfile
    command: /app/bin/entrypoint.sh
    environment:
      - DOCKER_PROFILE=api
      - ENVIRONMENT=dev
      - OTEL_FORCE_ENABLE=true
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318
    env_file:
      - .env
    ports:
      - "8000:8000"
    volumes:
      - ./robosystems:/app/robosystems # Mount code for hot reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://robosystems-api:8000/v1/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: always
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1"
        reservations:
          memory: 512m
          cpus: "0.5"
    profiles: ["api", "robosystems", "all"]

  # Graph API - Default LadybugDB Backend
  graph-api:
    container_name: robosystems-graph-api
    build:
      context: .
      dockerfile: Dockerfile
    command: /app/bin/entrypoint.sh
    environment:
      - DOCKER_PROFILE=ladybug-writer
      - ENVIRONMENT=dev
      - GRAPH_BACKEND_TYPE=ladybug
      - LBUG_PORT=8001
      - LBUG_DATABASE_PATH=/app/data/lbug-dbs
      - LBUG_NODE_TYPE=writer
      - CLUSTER_TIER=ladybug-standard
      - LBUG_DATABASES_PER_INSTANCE=${LBUG_DATABASES_PER_INSTANCE:-50}
    env_file:
      - .env
    ports:
      - "8001:8001"
    volumes:
      - ./robosystems:/app/robosystems # Mount code for hot reload
      - ./data/lbug-dbs:/app/data/lbug-dbs # LadybugDB embedded database for graph storage
      - ./data/staging:/app/data/staging # DuckDB embedded database for staging tables
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: always
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1.5"
        reservations:
          memory: 1g
          cpus: "1"
    profiles: ["graph-api", "graph-dbs", "robosystems", "all"]

  # Robosystems Worker
  worker:
    container_name: robosystems-worker
    build:
      context: .
      dockerfile: Dockerfile
    command: /app/bin/entrypoint.sh
    environment:
      - DOCKER_PROFILE=worker
      - ENVIRONMENT=dev
      - WORKER_QUEUE=default,critical,shared-extraction,shared-processing,shared-ingestion
      - RUN_MIGRATIONS=true
    env_file:
      - .env
    volumes:
      - ./robosystems:/app/robosystems # Mount code for hot reload
      - ./data/arelle:/app/robosystems/arelle # Writable Arelle cache directory
    restart: always
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "2"
        reservations:
          memory: 1g
          cpus: "1"
    profiles: ["worker", "robosystems", "all"]

  # Postgres - Database for RoboSystems (IAM)
  pg-iam:
    container_name: robosystems-pg-iam
    image: postgres:14
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=robosystems
    env_file:
      - .env
    ports:
      - 5432:5432
    volumes:
      - ./data/postgres/data:/var/lib/postgresql/data
      - ./bin/setup/postgres-init.sh:/docker-entrypoint-initdb.d/init-db.sh:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}"]
      interval: 1s
      timeout: 5s
      retries: 10
    restart: always
    deploy:
      resources:
        limits:
          memory: 1g
          cpus: "1"
        reservations:
          memory: 512m
          cpus: "0.5"
    profiles: ["pg", "robosystems", "all"]

  # Valkey - Cache for RoboSystems
  valkey:
    container_name: robosystems-valkey
    image: valkey/valkey:8.0-alpine
    ports:
      - 6379:6379
    volumes:
      - ./data/valkey:/data
    command: valkey-server
      --appendonly yes
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass ${VALKEY_AUTH_TOKEN:-valkey}
    env_file:
      - .env
    healthcheck:
      test: ["CMD", "valkey-cli", "-a", "${VALKEY_AUTH_TOKEN:-valkey}", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    restart: always
    deploy:
      resources:
        limits:
          memory: 768m
          cpus: "0.5"
        reservations:
          memory: 512m
          cpus: "0.25"
    profiles: ["valkey", "robosystems", "all"]

  # Graph API (Neo4j) - Alternative Neo4j Backend (Optional)
  graph-api-neo4j:
    container_name: robosystems-graph-api-neo4j
    build:
      context: .
      dockerfile: Dockerfile
    command: /app/bin/entrypoint.sh
    environment:
      - DOCKER_PROFILE=neo4j-writer
      - ENVIRONMENT=dev
      - GRAPH_BACKEND_TYPE=neo4j_community
      - NEO4J_URI=bolt://neo4j-db:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD}
      - GRAPH_API_PORT=8002
      - CLUSTER_TIER=enterprise
    env_file:
      - .env
    ports:
      - "8002:8002"
    volumes:
      - ./robosystems:/app/robosystems # Mount code for hot reload
      - ./data/staging:/app/data/staging # DuckDB embedded database for staging tables
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    depends_on:
      neo4j-db:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 1.5g
          cpus: "1"
        reservations:
          memory: 768m
          cpus: "0.5"
    profiles: ["neo4j", "graph-dbs"]

  # Neo4j Database - Graph Database Backend
  neo4j-db:
    container_name: robosystems-neo4j-db
    image: neo4j:5.25-community
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD-neo4jpassword}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_memory_pagecache_size=512M
      - NEO4J_dbms_memory_heap_initial__size=512M
      - NEO4J_dbms_memory_heap_max__size=1G
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true
    env_file:
      - .env
    ports:
      - "7474:7474" # HTTP Browser
      - "7687:7687" # Bolt Protocol
    volumes:
      - ./data/neo4j/data:/data
      - ./data/neo4j/logs:/logs
      - ./data/neo4j/import:/var/lib/neo4j/import
      - ./data/neo4j/plugins:/plugins
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: always
    deploy:
      resources:
        limits:
          memory: 3g
          cpus: "2"
        reservations:
          memory: 2g
          cpus: "1"
    profiles: ["neo4j", "graph-dbs"]

  # LocalStack - AWS services for RoboSystems
  localstack:
    container_name: robosystems-localstack
    image: localstack/localstack:3.0
    ports:
      - "4566:4566" # LocalStack edge port
    environment:
      # LocalStack configuration
      - SERVICES=s3,secretsmanager,iam,dynamodb
      - DEBUG=1
      - DATA_DIR=/var/lib/localstack
      - PERSISTENCE=1

      # S3 configuration
      - S3_SKIP_SIGNATURE_VALIDATION=1
      - S3_SKIP_KMS_KEY_VALIDATION=1

      # AWS credentials (dummy values for LocalStack)
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - AWS_DEFAULT_REGION=us-east-1

    volumes:
      - "./data/localstack:/var/lib/localstack"
      - "./bin/setup/localstack-init.sh:/etc/localstack/init/ready.d/init.sh"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always
    deploy:
      resources:
        limits:
          memory: 2g
          cpus: "1"
        reservations:
          memory: 1g
          cpus: "0.5"
    profiles: ["localstack", "robosystems", "all"]

  # OpenTelemetry Collector - Metrics and Tracing
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.106.0
    container_name: robosystems-otel-collector
    command: ["--config=/etc/otel/config.yaml"]
    volumes:
      - ./robosystems/middleware/otel/config/otel-collector-config.yaml:/etc/otel/config.yaml
    ports:
      - "4318:4318" # OTLP HTTP receiver
      - "8889:8889" # Prometheus exporter
    restart: always
    profiles: ["observability"]

  # Prometheus - Metrics and Tracing
  prometheus:
    image: prom/prometheus:v2.53.1
    container_name: robosystems-prometheus
    volumes:
      - ./robosystems/middleware/otel/config/prometheus.yaml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    restart: always
    profiles: ["observability"]

  # Grafana - Dashboard for Prometheus and OpenTelemetry
  grafana:
    image: grafana/grafana:11.2.1
    container_name: robosystems-grafana
    ports:
      - "4000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./robosystems/middleware/otel/config/datasources:/etc/grafana/provisioning/datasources
      - ./robosystems/middleware/otel/config/dashboards:/etc/grafana/provisioning/dashboards
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=password
      - GF_SECURITY_ADMIN_USER=admin
      - GF_INSTALL_PLUGINS=
    restart: always
    profiles: ["observability"]

  # RoboSystems App Frontend
  robosystems-app:
    container_name: robosystems-app
    build:
      context: ../robosystems-app
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=development
      - ENVIRONMENT=dev
      - NEXT_PUBLIC_ROBOSYSTEMS_API_URL=http://localhost:8000
      - NEXT_PUBLIC_ROBOSYSTEMS_APP_URL=http://localhost:3000
      - NEXT_PUBLIC_ROBOLEDGER_APP_URL=http://localhost:3001
      - NEXT_PUBLIC_ROBOINVESTOR_APP_URL=http://localhost:3002
      - NEXT_PUBLIC_MAINTENANCE_MODE=true
    ports:
      - 3000:3000
    volumes:
      - ../robosystems-app/src:/app/src:ro # Mount source code for hot reload
      - ../robosystems-app/public:/app/public:ro # Mount public assets
      - ../robosystems-app/package.json:/app/package.json:ro # Mount package.json
    restart: always
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
        reservations:
          memory: 256m
          cpus: "0.25"
    profiles: ["robosystems-app", "apps", "all"]

  # RoboLedger App Frontend
  roboledger-app:
    container_name: roboledger-app
    build:
      context: ../roboledger-app
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=development
      - ENVIRONMENT=dev
      - NEXT_PUBLIC_ROBOSYSTEMS_API_URL=http://localhost:8000
      - NEXT_PUBLIC_ROBOSYSTEMS_APP_URL=http://localhost:3000
      - NEXT_PUBLIC_ROBOLEDGER_APP_URL=http://localhost:3001
      - NEXT_PUBLIC_ROBOINVESTOR_APP_URL=http://localhost:3002
      - NEXT_PUBLIC_MAINTENANCE_MODE=true
    ports:
      - 3001:3000
    volumes:
      - ../roboledger-app/src:/app/src:ro # Mount source code for hot reload
      - ../roboledger-app/public:/app/public:ro # Mount public assets
      - ../roboledger-app/package.json:/app/package.json:ro # Mount package.json
    restart: always
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
        reservations:
          memory: 256m
          cpus: "0.25"
    profiles: ["roboledger-app", "apps", "all"]

  # RoboInvestor App Frontend
  roboinvestor-app:
    container_name: roboinvestor-app
    build:
      context: ../roboinvestor-app
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=development
      - ENVIRONMENT=dev
      - NEXT_PUBLIC_ROBOSYSTEMS_API_URL=http://localhost:8000
      - NEXT_PUBLIC_ROBOSYSTEMS_APP_URL=http://localhost:3000
      - NEXT_PUBLIC_ROBOLEDGER_APP_URL=http://localhost:3001
      - NEXT_PUBLIC_ROBOINVESTOR_APP_URL=http://localhost:3002
      - NEXT_PUBLIC_MAINTENANCE_MODE=true
    ports:
      - 3002:3000
    volumes:
      - ../roboinvestor-app/src:/app/src:ro # Mount source code for hot reload
      - ../roboinvestor-app/public:/app/public:ro # Mount public assets
      - ../roboinvestor-app/package.json:/app/package.json:ro # Mount package.json
    restart: always
    deploy:
      resources:
        limits:
          memory: 512m
          cpus: "0.5"
        reservations:
          memory: 256m
          cpus: "0.25"
    profiles: ["roboinvestor-app", "apps", "all"]

volumes:
  prometheus_data:
  grafana_data:
